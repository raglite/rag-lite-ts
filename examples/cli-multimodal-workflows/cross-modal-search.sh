#!/bin/bash

# Cross-Modal Search Examples
# This script demonstrates the power of cross-modal search in multimodal mode

echo "=================================================="
echo "RAG-lite Cross-Modal Search Examples"
echo "=================================================="
echo ""

echo "What is Cross-Modal Search?"
echo "---------------------------"
echo ""
echo "Cross-modal search allows you to:"
echo "  • Find images using text queries"
echo "  • Find text using image descriptions"
echo "  • Search across both content types simultaneously"
echo "  • Leverage semantic similarity in a unified embedding space"
echo ""
echo "This is only possible in multimodal mode with CLIP models."
echo ""

# Prerequisite check
echo "Prerequisites:"
echo "  1. Content must be ingested in multimodal mode"
echo "  2. Run multimodal-ingestion.sh first if you haven't already"
echo ""
read -p "Press Enter to continue with examples..."
echo ""

# Example 1: Text query finding images
echo "=================================================="
echo "Example 1: Text Query Finding Images"
echo "=================================================="
echo ""
echo "Scenario: You want to find images of red vehicles"
echo ""
echo "Command: raglite search \"red sports car\" --content-type image"
echo ""
echo "What happens:"
echo "  1. Your text query is embedded using CLIP text encoder"
echo "  2. System searches the unified embedding space"
echo "  3. Returns images with similar semantic meaning"
echo "  4. Results filtered to show only images"
echo ""

raglite search "red sports car" --content-type image

echo ""
echo "✓ Found images semantically similar to 'red sports car'"
echo ""

# Example 2: Finding both text and images
echo "=================================================="
echo "Example 2: Finding Both Text and Images"
echo "=================================================="
echo ""
echo "Scenario: You want all content related to vehicles"
echo ""
echo "Command: raglite search \"vehicles and transportation\""
echo ""
echo "What happens:"
echo "  1. Query embedded in unified space"
echo "  2. Returns both text documents and images"
echo "  3. Results ranked by semantic similarity"
echo "  4. Mixed content types in results"
echo ""

raglite search "vehicles and transportation"

echo ""
echo "✓ Found mixed content types related to vehicles"
echo ""

# Example 3: Nature and landscapes
echo "=================================================="
echo "Example 3: Searching for Natural Landscapes"
echo "=================================================="
echo ""
echo "Scenario: Find content about ocean views"
echo ""
echo "Command: raglite search \"blue ocean water\" --top-k 5"
echo ""

raglite search "blue ocean water" --top-k 5

echo ""
echo "✓ Found content related to ocean landscapes"
echo ""

# Example 4: Abstract concepts
echo "=================================================="
echo "Example 4: Abstract Concept Search"
echo "=================================================="
echo ""
echo "Scenario: Search for content about 'adventure'"
echo ""
echo "Command: raglite search \"adventure and exploration\""
echo ""
echo "What makes this powerful:"
echo "  • CLIP understands abstract concepts"
echo "  • Can match images that convey 'adventure' feeling"
echo "  • Finds text discussing adventure themes"
echo "  • Semantic understanding beyond keywords"
echo ""

raglite search "adventure and exploration"

echo ""

# Example 5: Color-based search
echo "=================================================="
echo "Example 5: Color-Based Image Search"
echo "=================================================="
echo ""
echo "Scenario: Find images with specific colors"
echo ""
echo "Command: raglite search \"bright red color\" --content-type image"
echo ""
echo "CLIP models understand:"
echo "  • Color descriptions"
echo "  • Visual attributes"
echo "  • Compositional concepts"
echo ""

raglite search "bright red color" --content-type image

echo ""

# Example 6: Combining with reranking
echo "=================================================="
echo "Example 6: Cross-Modal Search with Reranking"
echo "=================================================="
echo ""
echo "Scenario: High-quality results for complex queries"
echo ""
echo "Command: raglite search \"mountain sunset scenery\" --rerank --top-k 3"
echo ""
echo "Reranking improves results by:"
echo "  • Refining initial vector search results"
echo "  • Using additional semantic signals"
echo "  • Providing more accurate ranking"
echo ""

raglite search "mountain sunset scenery" --rerank --top-k 3

echo ""

# Use case examples
echo "=================================================="
echo "Real-World Use Cases"
echo "=================================================="
echo ""
echo "1. Digital Asset Management"
echo "   - Find product images by description"
echo "   - Search documentation and product photos together"
echo "   - Organize visual and textual content"
echo ""
echo "2. Research and Education"
echo "   - Find diagrams related to concepts"
echo "   - Search lecture notes and slides together"
echo "   - Discover visual examples for topics"
echo ""
echo "3. Content Creation"
echo "   - Find stock photos matching article topics"
echo "   - Search reference images and descriptions"
echo "   - Organize creative assets"
echo ""
echo "4. E-commerce"
echo "   - Search products by description"
echo "   - Find similar items visually"
echo "   - Match customer queries to product images"
echo ""

# Tips and best practices
echo "=================================================="
echo "Tips for Effective Cross-Modal Search"
echo "=================================================="
echo ""
echo "✓ Be descriptive in your queries"
echo "  - Good: \"red sports car on city street\""
echo "  - Better: \"bright red sports car parked on urban street\""
echo ""
echo "✓ Use visual attributes"
echo "  - Colors: \"blue\", \"bright red\", \"dark green\""
echo "  - Textures: \"smooth\", \"rough\", \"glossy\""
echo "  - Compositions: \"centered\", \"landscape view\""
echo ""
echo "✓ Leverage semantic concepts"
echo "  - Emotions: \"peaceful\", \"exciting\", \"dramatic\""
echo "  - Themes: \"adventure\", \"nature\", \"technology\""
echo "  - Styles: \"modern\", \"vintage\", \"minimalist\""
echo ""
echo "✓ Filter by content type when needed"
echo "  - Use --content-type image for visual-only results"
echo "  - Use --content-type text for document-only results"
echo "  - Omit filter for comprehensive results"
echo ""
echo "✓ Adjust result count based on use case"
echo "  - Use --top-k 3 for quick previews"
echo "  - Use --top-k 20 for comprehensive searches"
echo "  - Default is 10 results"
echo ""

echo "=================================================="
echo "Cross-Modal Search Examples Complete!"
echo "=================================================="
echo ""
echo "Key Takeaways:"
echo "  • Cross-modal search works in unified embedding space"
echo "  • Text queries can find semantically similar images"
echo "  • CLIP models understand visual and semantic concepts"
echo "  • Filtering and reranking enhance result quality"
echo ""
echo "Next Steps:"
echo "  • Try your own queries with your content"
echo "  • Experiment with different content type filters"
echo "  • Explore advanced-workflows.sh for complex scenarios"
echo ""
