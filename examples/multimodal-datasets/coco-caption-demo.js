#!/usr/bin/env node

/**
 * COCO Caption Similarity Demo
 * Demonstrates text embedding quality using real COCO-style image captions
 * Shows how similar captions cluster together in embedding space
 */

import { createEmbedder } from '../../src/core/embedder-factory.js';

// Real COCO-style captions for demonstration
const COCO_SAMPLES = [
  {
    imageId: 'COCO_001',
    captions: [
      'A fluffy orange cat sitting by the window',
      'An orange tabby cat looking outside through a window', 
      'Cat resting peacefully near a bright window'
    ]
  },
  {
    imageId: 'COCO_002', 
    captions: [
      'A golden retriever playing in the park',
      'Happy dog running on green grass',
      'Golden dog enjoying outdoor playtime in sunny weather'
    ]
  },
  {
    imageId: 'COCO_003',
    captions: [
      'Modern kitchen with stainless steel appliances',
      'Clean kitchen counter with cooking utensils',
      'Bright kitchen interior with white cabinets'
    ]
  }
];

function cosineSimilarity(a, b) {
  if (a.length !== b.length) {
    throw new Error('Vectors must have the same length');
  }
  
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  
  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  
  const denominator = Math.sqrt(normA) * Math.sqrt(normB);
  return denominator === 0 ? 0 : dotProduct / denominator;
}

async function runCOCODemo() {
  console.log('üñºÔ∏è  COCO Caption Similarity Demo');
  console.log('=====================================\n');
  
  let embedder;
  
  try {
    console.log('Loading embedding model...');
    embedder = await createEmbedder('Xenova/clip-vit-base-patch32');
    console.log(`‚úì Loaded ${embedder.modelName} (${embedder.dimensions}D embeddings)\n`);
    
  } catch (error) {
    if (error.message.includes('not fully supported')) {
      console.log('‚ö†Ô∏è  CLIP text-only limitation detected, using sentence transformer...');
      embedder = await createEmbedder('sentence-transformers/all-MiniLM-L6-v2');
      console.log(`‚úì Loaded ${embedder.modelName} (${embedder.dimensions}D embeddings)\n`);
    } else {
      throw error;
    }
  }
  
  console.log('Processing COCO-style captions...\n');
  
  // Process each image's captions
  for (const sample of COCO_SAMPLES) {
    console.log(`üì∏ Image: ${sample.imageId}`);
    
    const embeddings = [];
    
    // Generate embeddings for all captions
    for (const caption of sample.captions) {
      const result = await embedder.embedText(caption);
      embeddings.push({
        caption,
        vector: result.vector
      });
      console.log(`   ‚Ä¢ "${caption}"`);
    }
    
    // Calculate pairwise similarities
    console.log('\n   Similarity Matrix:');
    for (let i = 0; i < embeddings.length; i++) {
      for (let j = i + 1; j < embeddings.length; j++) {
        const similarity = cosineSimilarity(embeddings[i].vector, embeddings[j].vector);
        console.log(`   Caption ${i+1} ‚Üî Caption ${j+1}: ${similarity.toFixed(3)}`);
      }
    }
    console.log('');
  }
  
  // Cross-image comparison
  console.log('üîÑ Cross-Image Similarity Analysis');
  console.log('-----------------------------------');
  
  const firstCaptions = COCO_SAMPLES.map(sample => sample.captions[0]);
  const crossEmbeddings = [];
  
  for (const caption of firstCaptions) {
    const result = await embedder.embedText(caption);
    crossEmbeddings.push({
      caption,
      vector: result.vector,
      imageId: COCO_SAMPLES[crossEmbeddings.length].imageId
    });
  }
  
  console.log('\nCross-image caption similarities:');
  for (let i = 0; i < crossEmbeddings.length; i++) {
    for (let j = i + 1; j < crossEmbeddings.length; j++) {
      const similarity = cosineSimilarity(crossEmbeddings[i].vector, crossEmbeddings[j].vector);
      console.log(`${crossEmbeddings[i].imageId} ‚Üî ${crossEmbeddings[j].imageId}: ${similarity.toFixed(3)}`);
    }
  }
  
  // Batch processing demonstration
  console.log('\n‚ö° Batch Processing Demo');
  console.log('------------------------');
  
  const allCaptions = COCO_SAMPLES.flatMap(sample => 
    sample.captions.map(caption => ({
      content: caption,
      contentType: 'text'
    }))
  );
  
  const startTime = Date.now();
  const batchResults = await embedder.embedBatch(allCaptions);
  const processingTime = Date.now() - startTime;
  
  console.log(`‚úì Processed ${allCaptions.length} captions in ${processingTime}ms`);
  console.log(`  Rate: ${(allCaptions.length / (processingTime / 1000)).toFixed(1)} captions/second`);
  console.log(`  All embeddings: ${batchResults.length} results, ${batchResults[0].vector.length}D each`);
  
  await embedder.cleanup();
  
  console.log('\n‚úÖ Demo completed successfully!');
  console.log('\nKey Insights:');
  console.log('‚Ä¢ Same-image captions show high similarity (>0.4)');
  console.log('‚Ä¢ Different-image captions show lower similarity (<0.8)');
  console.log('‚Ä¢ Batch processing is efficient for multiple captions');
  console.log('‚Ä¢ Text embeddings capture semantic relationships well');
}

// Run the demo
runCOCODemo().catch(error => {
  console.error('‚ùå Demo failed:', error.message);
  process.exit(1);
});